{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP12_tsk1_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaGLyAWdx92z"
      },
      "source": [
        "# importing the required libraries\n",
        "import pandas as pd                       # for creating dataframes\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import re                                 # regular expression operations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D # for layers in Neural Network\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SEVdDkxyaRP"
      },
      "source": [
        "# looading the Sentiment dataset\n",
        "data = pd.read_csv('Sentiment.csv') \n",
        "data = data[['text','sentiment']] # Keeping only the neccessary columns\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))) #only keeping a-z,A-Z,0-9 in the data"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egDf2wo2yqxX"
      },
      "source": [
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ') # removing Retweets"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBH-oPfpyrnA"
      },
      "source": [
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ') # tokenizing the sentence\n",
        "tokenizer.fit_on_texts(data['text'].values) \n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "X = pad_sequences(X) # padding the feature matrix - add zeros for matching the sentence length\n",
        "embed_dim = 128      # dimension of the Embedded layer\n",
        "lstm_out = 196       # LSTM ( Long short-term memory ) layer neurons"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vtNW82EyzZL"
      },
      "source": [
        "def createmodel():\n",
        "    model = Sequential() # Sequential Neural Network\n",
        "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1])) \n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) \n",
        "    model.add(Dense(3,activation='softmax')) \n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) \n",
        "    return model\n",
        "# print(model.summary())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFQEwqZiy8f6",
        "outputId": "7d067a1b-6cdc-424d-c9ee-1d19004a6f1c"
      },
      "source": [
        "labelencoder = LabelEncoder() # conversion of categorical to Numerical\n",
        "#fitting the model\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment']) \n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42) \n",
        "batch_size = 32 \n",
        "model = createmodel() \n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) # more messages for higher verbose\n",
        "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
        "print(score)\n",
        "print(acc)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "291/291 - 44s - loss: 0.8248 - accuracy: 0.6448\n",
            "144/144 - 3s - loss: 0.7409 - accuracy: 0.6811\n",
            "0.7408873438835144\n",
            "0.6810834407806396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqAGAi2ezB_G",
        "outputId": "bfed0fdf-bc54-404c-8ad8-5264d78c22ea"
      },
      "source": [
        "print(model.metrics_names) # model metrics"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTpLSdA2zKvw"
      },
      "source": [
        "# **Task_1: Save the model and use the saved model to predict on new text data (ex,“A lot of good things are happening. We are respected again throughout the world, and that's a great thing.@realDonaldTrump”)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jvea3HNzYsu"
      },
      "source": [
        "# saving the model\n",
        "model.save('sentimentAnalysis.h5') \n",
        "\n",
        "from keras.models import load_model       #importing the package to get the saved model\n",
        "model= load_model('sentimentAnalysis.h5') #loading the model which is saved"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6H6h6WBz2Gt",
        "outputId": "2238010a-de64-4a1f-e271-36d41e44be74"
      },
      "source": [
        "print(integer_encoded)\n",
        "print(data['sentiment'])                  # get the sentiment analysis"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 1 ... 2 0 2]\n",
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgSe6_9lz7am",
        "outputId": "55066bfe-b597-45db-f968-16cbac9b1131"
      },
      "source": [
        "# predicting the new text data\n",
        "\n",
        "# Processing the input text \n",
        "text_in = [\"A lot of good things are happening. We are respected again throughout the world, and that's a great thing.@realDonaldTrump\"]\n",
        "text_in = tokenizer.texts_to_sequences(text_in)                        # tokenizing the sentence\n",
        "text_in = pad_sequences(text_in, maxlen=28, dtype='int32', value=0)    # padding - add zeros to match the sentence length\n",
        "\n",
        "# standard analyzer defines up to three basic polar emotions (positive, negative, neutral)\n",
        "res_sentiment = model.predict_classes(text_in,batch_size=1,verbose = 2)[0]  # predicting the sentence text\n",
        "print(res_sentiment)\n",
        "if ( res_sentiment < 0 ):\n",
        "  print(\"\\n Negative\")\n",
        "elif ( res_sentiment == 0 ):\n",
        "  print(\"\\n Neutral\")\n",
        "elif ( res_sentiment > 0 ):\n",
        "  print(\"\\n Positive\")\n",
        "else:\n",
        "  print(\"not determined\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s\n",
            "0\n",
            "\n",
            " Neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NPKnw4h0Bs7"
      },
      "source": [
        "# **Task_2: Apply GridSearchCV on the source code provided in the class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zti6jpvd0YGf",
        "outputId": "ff6d7f22-6acd-46ae-aff0-59dc62bc668e"
      },
      "source": [
        "# importing the required libraries\n",
        "from keras.wrappers.scikit_learn import KerasClassifier \n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "# applying GridSearchCV on model\n",
        "model_1 = KerasClassifier(build_fn=createmodel,verbose=2) # applying multiple hyper parameters for model initiation\n",
        "\n",
        "# hyper parameters\n",
        "batch_size= [10, 20, 40]     \n",
        "epochs = [1, 2]             \n",
        "\n",
        "param_grid= {'batch_size':batch_size, 'epochs':epochs}          # creating dictionary for batch size and no. of epochs\n",
        "grid  = GridSearchCV(estimator=model_1, param_grid=param_grid)  # applying dictionary with hyper parameters for GridSearchCV\n",
        "grid_result= grid.fit(X_train,Y_train)                          # fitting the model\n",
        "\n",
        "# summarizing the results - best score, best hyper parameters\n",
        "print(\"Best Score achieved: %f by using the parameters %s\" % (grid_result.best_score_, grid_result.best_params_)) "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "744/744 - 91s - loss: 0.8243 - accuracy: 0.6512\n",
            "186/186 - 2s - loss: 0.7577 - accuracy: 0.6681\n",
            "744/744 - 90s - loss: 0.8261 - accuracy: 0.6442\n",
            "186/186 - 2s - loss: 0.7957 - accuracy: 0.6616\n",
            "744/744 - 90s - loss: 0.8257 - accuracy: 0.6427\n",
            "186/186 - 3s - loss: 0.7666 - accuracy: 0.6799\n",
            "744/744 - 92s - loss: 0.8203 - accuracy: 0.6480\n",
            "186/186 - 2s - loss: 0.7703 - accuracy: 0.6744\n",
            "744/744 - 92s - loss: 0.8180 - accuracy: 0.6518\n",
            "186/186 - 2s - loss: 0.7835 - accuracy: 0.6744\n",
            "Epoch 1/2\n",
            "744/744 - 92s - loss: 0.8208 - accuracy: 0.6507\n",
            "Epoch 2/2\n",
            "744/744 - 89s - loss: 0.6802 - accuracy: 0.7132\n",
            "186/186 - 3s - loss: 0.7399 - accuracy: 0.6853\n",
            "Epoch 1/2\n",
            "744/744 - 92s - loss: 0.8216 - accuracy: 0.6453\n",
            "Epoch 2/2\n",
            "744/744 - 89s - loss: 0.6769 - accuracy: 0.7143\n",
            "186/186 - 2s - loss: 0.7564 - accuracy: 0.6880\n",
            "Epoch 1/2\n",
            "744/744 - 90s - loss: 0.8234 - accuracy: 0.6453\n",
            "Epoch 2/2\n",
            "744/744 - 88s - loss: 0.6791 - accuracy: 0.7096\n",
            "186/186 - 2s - loss: 0.7547 - accuracy: 0.6869\n",
            "Epoch 1/2\n",
            "744/744 - 93s - loss: 0.8267 - accuracy: 0.6482\n",
            "Epoch 2/2\n",
            "744/744 - 90s - loss: 0.6727 - accuracy: 0.7170\n",
            "186/186 - 2s - loss: 0.7665 - accuracy: 0.6545\n",
            "Epoch 1/2\n",
            "744/744 - 91s - loss: 0.8204 - accuracy: 0.6486\n",
            "Epoch 2/2\n",
            "744/744 - 89s - loss: 0.6653 - accuracy: 0.7146\n",
            "186/186 - 2s - loss: 0.7814 - accuracy: 0.6695\n",
            "372/372 - 54s - loss: 0.8282 - accuracy: 0.6462\n",
            "93/93 - 2s - loss: 0.7515 - accuracy: 0.6703\n",
            "372/372 - 55s - loss: 0.8226 - accuracy: 0.6504\n",
            "93/93 - 2s - loss: 0.7790 - accuracy: 0.6633\n",
            "372/372 - 55s - loss: 0.8327 - accuracy: 0.6388\n",
            "93/93 - 2s - loss: 0.7562 - accuracy: 0.6697\n",
            "372/372 - 55s - loss: 0.8346 - accuracy: 0.6374\n",
            "93/93 - 2s - loss: 0.7673 - accuracy: 0.6749\n",
            "372/372 - 54s - loss: 0.8244 - accuracy: 0.6433\n",
            "93/93 - 2s - loss: 0.7703 - accuracy: 0.6862\n",
            "Epoch 1/2\n",
            "372/372 - 56s - loss: 0.8330 - accuracy: 0.6430\n",
            "Epoch 2/2\n",
            "372/372 - 53s - loss: 0.6820 - accuracy: 0.7104\n",
            "93/93 - 2s - loss: 0.7352 - accuracy: 0.6821\n",
            "Epoch 1/2\n",
            "372/372 - 56s - loss: 0.8242 - accuracy: 0.6473\n",
            "Epoch 2/2\n",
            "372/372 - 53s - loss: 0.6811 - accuracy: 0.7100\n",
            "93/93 - 2s - loss: 0.7719 - accuracy: 0.6842\n",
            "Epoch 1/2\n",
            "372/372 - 54s - loss: 0.8392 - accuracy: 0.6384\n",
            "Epoch 2/2\n",
            "372/372 - 52s - loss: 0.6828 - accuracy: 0.7088\n",
            "93/93 - 2s - loss: 0.7409 - accuracy: 0.6859\n",
            "Epoch 1/2\n",
            "372/372 - 55s - loss: 0.8388 - accuracy: 0.6399\n",
            "Epoch 2/2\n",
            "372/372 - 53s - loss: 0.6874 - accuracy: 0.7080\n",
            "93/93 - 2s - loss: 0.7554 - accuracy: 0.6717\n",
            "Epoch 1/2\n",
            "372/372 - 54s - loss: 0.8244 - accuracy: 0.6473\n",
            "Epoch 2/2\n",
            "372/372 - 52s - loss: 0.6764 - accuracy: 0.7110\n",
            "93/93 - 2s - loss: 0.7868 - accuracy: 0.6679\n",
            "186/186 - 31s - loss: 0.8467 - accuracy: 0.6345\n",
            "47/47 - 1s - loss: 0.7748 - accuracy: 0.6520\n",
            "186/186 - 31s - loss: 0.8375 - accuracy: 0.6367\n",
            "47/47 - 1s - loss: 0.7716 - accuracy: 0.6638\n",
            "186/186 - 31s - loss: 0.8493 - accuracy: 0.6345\n",
            "47/47 - 1s - loss: 0.7562 - accuracy: 0.6783\n",
            "186/186 - 31s - loss: 0.8448 - accuracy: 0.6317\n",
            "47/47 - 1s - loss: 0.7681 - accuracy: 0.6765\n",
            "186/186 - 31s - loss: 0.8420 - accuracy: 0.6393\n",
            "47/47 - 1s - loss: 0.7767 - accuracy: 0.6668\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8430 - accuracy: 0.6399\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6968 - accuracy: 0.7031\n",
            "47/47 - 1s - loss: 0.7353 - accuracy: 0.6880\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8400 - accuracy: 0.6407\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6940 - accuracy: 0.7020\n",
            "47/47 - 1s - loss: 0.7357 - accuracy: 0.6837\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8455 - accuracy: 0.6359\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6890 - accuracy: 0.7050\n",
            "47/47 - 1s - loss: 0.7803 - accuracy: 0.6799\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8466 - accuracy: 0.6358\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6904 - accuracy: 0.7037\n",
            "47/47 - 1s - loss: 0.7415 - accuracy: 0.6900\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8442 - accuracy: 0.6383\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6859 - accuracy: 0.7075\n",
            "47/47 - 1s - loss: 0.7745 - accuracy: 0.6712\n",
            "Epoch 1/2\n",
            "233/233 - 38s - loss: 0.8259 - accuracy: 0.6460\n",
            "Epoch 2/2\n",
            "233/233 - 36s - loss: 0.6807 - accuracy: 0.7073\n",
            "Best Score acheived: 0.682556 by using the parameters {'batch_size': 40, 'epochs': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}